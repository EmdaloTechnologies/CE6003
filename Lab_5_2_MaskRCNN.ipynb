{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_5_2_MaskRCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kgNYa1nk_fR",
        "colab_type": "text"
      },
      "source": [
        "# Mask R-CNN\n",
        "\n",
        "In this lab, we're going to look at [Mask R-CNN](https://arxiv.org/abs/1703.06870). \n",
        "\n",
        "![Mask R-CNN from our video lectures](https://github.com/EmdaloTechnologies/CE6003/images/lab5/MaskRCNN.png?raw=1)\n",
        "\n",
        "The implementation of Mask R-CNN we are going to use is one by [Matterport](https://matterport.com/), a company specialising in 3D capture.  Their implementation is based on TensorFlow 1.x using the Keras API, and is available on Github at https://github.com/matterport/Mask_RCNN\n",
        "\n",
        "The model generates bounding boxes and segmentation masks for each instance of an object in the image. It's based on Feature Pyramid Network (FPN) and a ResNet101 as its base classifier. As it is quite a large network, it is not feasible for us to train Mask-RCNN within the Colab environment - so our usage here is restricted to demonstrating its powerful inference capabilities.  However, the GitHub link above does include information on downloading and training Mask R-CNN, including a Jupyter Notebook tutorial on training.\n",
        "\n",
        "![Mask R-CNN Examples](https://github.com/EmdaloTechnologies/CE6003/images/lab5/MaskRCNN_examples.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAxfODRmke4k",
        "colab_type": "text"
      },
      "source": [
        "First, we'll import TensorFlow 1.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNUNnVmUkfCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH3NSjxOCK6H",
        "colab_type": "text"
      },
      "source": [
        "*To* ensure these labs run as fast as possible, from the menu above select **Edit > Notebook settings or Runtime > Change runtime type** and select GPU as the Hardware accelerator option.\n",
        "\n",
        "Let's test that we are running using the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An5Nr1LECL0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy7dcIXjln8Y",
        "colab_type": "text"
      },
      "source": [
        "**If** this outputs '', then we are running on CPU only. If it outputs something like '/device:GPU:0' then we are running on GPU. If you see something like ...\n",
        "\n",
        "    Failed to assign a backend\n",
        "    No backend with GPU available. WOuld you like to use a runtime with no accelerator?\n",
        "\n",
        "This suggests that many other users have all the GPU resources on colab occupied at the moment, so perhaps try later or try using with the TPU instead.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSntKG-sCQwZ",
        "colab_type": "text"
      },
      "source": [
        "Now, we'll continue to import the other Python libraries we need for this demo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiazhMvPi8tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import skimage.io\n",
        "import random\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ENfNj1Wlsz1",
        "colab_type": "text"
      },
      "source": [
        "# Matterport implementation of Mask R-CNN\n",
        "\n",
        "We'll clone the Mask R-CNN code directly from the Matterport GitHub repository. If we have run this step already, you'll see an error of the form `fatal: destination path 'Mask_RCNN' already exists and is not an empty directory` which you can safely ignore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8WY8546XeIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSRAiJLyYteY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"./Mask_RCNN\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "\n",
        "# Import COCO config - this is use to configure our model later on\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "import coco"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7rvYYZGn7cK",
        "colab_type": "text"
      },
      "source": [
        "# Pre-trained weights - \"Here's one we made earlier...\"\n",
        "\n",
        "We can leverage the fact that the model was already pre-trained using the Microsoft COCO dataset, and skip training here.\n",
        "\n",
        "COCO, or Common Objects in Context, is a wonderful densely labelled large dataset for object detection, segmentation, and captioning. \n",
        "\n",
        "\n",
        "![COCO Examples](http://cocodataset.org/images/coco-examples.jpg)\n",
        "\n",
        "\n",
        "\n",
        "COCO has several features:\n",
        "\n",
        "* Object segmentation;\n",
        "* Recognition in context;\n",
        "* Superpixel stuff segmentation;\n",
        "* 330K images (>200K labeled);\n",
        "* 1.5 million object instances;\n",
        "* 80 object categories;\n",
        "* 91 stuff categories;\n",
        "* 5 captions per imag\n",
        "* 250,000 people with keypoints.\n",
        "\n",
        "You can read more about COCO at http://cocodataset.org/#home\n",
        "\n",
        "HDF5 (.h5, .hdf5) is a file format suitable for storing large multidimensional numeric arrays (e.g. models, data files). HDF stands for Hierarchical Data Format, and can store everything about your model, including:\n",
        "\n",
        "* The architecture of the model;\n",
        "* The weights of the model;\n",
        "* The training configuration (loss, optimizer);\n",
        "* The state of the optimizer, so you can resume training exactly where you left off.\n",
        "\n",
        "You can read more about the HDF5 file format at http://docs.h5py.org/en/stable/quick.html, and at the Keras API for loading and saving models at https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXbYoHxkZAqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcqPNsdlqkV4",
        "colab_type": "text"
      },
      "source": [
        "We'll create a list of class names for COCO, that we can use later in the lab. We have 81 separate classes, and so 81 separate names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eepIdUpXqk3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "len(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJxpC5Zcn2zo",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the size of our downloaded weights file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvhvTalQhy0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lh /content/Mask_RCNN/mask_rcnn_coco.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpRocpkM49Ec",
        "colab_type": "text"
      },
      "source": [
        "That's quite a lot of weight parameters when you think about it!  \n",
        "\n",
        "We need to set our batch size to 1 for inference, so we'll subclass the config structure used in the Mask-RCNN code as follows, and we'll output the configuration - which will help us understand what type of network we're dealing with..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e--kh8mZExf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHkpWUkY5NH1",
        "colab_type": "text"
      },
      "source": [
        "Okay, we can see our base network (\"BACKBONE\") is *resnet101*, a 101-layer ResNet model. We have a mask shape (\"MASK_SHAPE\") of 28x28 pixels. We have a learning rate of 0.001 and a learning momentum of 0.9.\n",
        "\n",
        "Our model has been trained with 81 classes (\"NUM_CLASSES\"), and we can see that we conveniently setup an array of class names earlier..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTjpkWxt63AM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybOe46L3sg2J",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Model Creation, and Loading Weights\n",
        "\n",
        "Now we need to create our model (using the Mask R-CNN code API) and then load the pre-trained weights into our model.\n",
        "\n",
        "The Matterport code uses Keras, but the Keras version on Colab warns about some deprecated functions in TensorFlow 1.x that are changing name in TensorFlow 2.x.  As we don't care about this, we'll disable most of these warnings. You may still see some of the form `WARNING: ... is deprecated and will be removed in a future version` but you can safely ignore these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBp2GYbpf0cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Disable warnings about deprecated TF 1.x functions vis-a-vis TF 2.x API\n",
        "try:\n",
        "    from tensorflow.python.util import module_wrapper as deprecation\n",
        "except ImportError:\n",
        "    from tensorflow.python.util import deprecation_wrapper as deprecation\n",
        "deprecation._PER_MODULE_WARNING_LIMIT = 0\n",
        "\n",
        "\n",
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrj1omYaS2FP",
        "colab_type": "text"
      },
      "source": [
        "Let's take a quick peek at our model. It is hidden as a `keras_model` variable within our mrcnn `model`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxyxyhLjR_f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.keras_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIk9dISSTCOE",
        "colab_type": "text"
      },
      "source": [
        "64 million parameters, compared to ~100K for our MNIST ANN.  So it is quite a large network. However, VGG19, which was a popular *base* classifier, is approximately 140 million parameters, so the state of the art has improved (amongst other ideas, through the use ResNet and skip connections) in reducing the size of our deep nets at the same time as improving their performance and capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kASVk6vypsO0",
        "colab_type": "text"
      },
      "source": [
        "# Performing Inference\n",
        "\n",
        "At this stage, we can take any random image and pass it through our model for inference.\n",
        "\n",
        "You can execute the following cell as many times as you like, and it will pull a random image from the images folder, and perform inference on it, displaying the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwFQ5RSPgAIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a random image from the images folder\n",
        "file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "print(\"Looking at %s\" % (file_names))\n",
        "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
        "\n",
        "# Run detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3loGqLIR7YZg",
        "colab_type": "text"
      },
      "source": [
        "## Examing the results in more detail\n",
        "\n",
        "The results dictionary, `r` is interesting. We can see it has a number of items in it, idenfified the by the keys `rois`, `class_ids`, `scores`, and `masks`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO4IwEyK7cN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6uRazCj-3ra",
        "colab_type": "text"
      },
      "source": [
        "We can easily see how many objects we identified and what they were..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc3Wecmb-4G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numObjects = r['class_ids'].shape[0]\n",
        "\n",
        "print(\"We identified %d objects:\\n\" % numObjects, end=\" \")\n",
        "\n",
        "count = 0\n",
        "for class_id in r['class_ids']:\n",
        "  if (count == 10):\n",
        "    print(\"\\n\", end = \" \")\n",
        "    count = 0\n",
        "  else:\n",
        "    count += 1 \n",
        "  print(\"%s\" % class_names[class_id], end = \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzyx0qIwRPP7",
        "colab_type": "text"
      },
      "source": [
        "Thr rois key is used to get the *region of interest* bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuLh4ylYUhvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r['rois']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UTidxjw7u33",
        "colab_type": "text"
      },
      "source": [
        "The bounding box format is `[topLeft_x, topLeft_y, bottomRight_x, bottomRight_y]`.\n",
        "\n",
        "Now, let's take a look at the masks item in more detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAsDTpd70R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = r['masks']\n",
        "mask = mask.astype(int)\n",
        "print(\"Our mask shape (x_width, y_height, num_classes) is \", mask.shape, \" - it has the same width and height as the input image.\")\n",
        "print(\"Let's plot mask 0...\")\n",
        "plt.imshow(mask[:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c3Qp34CW6dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(tl_x, tl_y, br_x, br_y) = r['rois'][0]\n",
        "print(\"\\nLet's plot again, this time restricting to just the bounding box (%d, %d, %d, %d)...\" % (tl_x, tl_y, br_x, br_y))\n",
        "\n",
        "plt.imshow(mask[tl_x:br_x, tl_y:br_y, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El7du-NO8BuQ",
        "colab_type": "text"
      },
      "source": [
        "Masks is the same size as our input image, but note the number of channels (the third parameter above) -- this corresponds to the number of objects we detected.  In our masks, we have arrays of 0s and 1s which delineate the shape of each object.\n",
        "\n",
        "The following cell will allow you to iterate through the shapes and example each one - set i to the index you want to look at..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7KLLjEU8TDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0; # set i to the individual shape you want to look at...\n",
        "\n",
        "class_id = r['class_ids'][i]\n",
        "print(\"There are %d shape%s in this image, we're going to look at shape %d.\" % (mask.shape[2], \"s\" if mask.shape[2] != 1 else \"\", i))\n",
        "print(\"Shape %d is class_id %d, which has the label \\\"%s\\\"\\n\" % (i, class_id, class_names[class_id]))\n",
        "\n",
        "temp = image.copy()\n",
        "for j in range(temp.shape[2]):\n",
        "  temp[:,:,j] = temp[:,:,j] * mask[:,:,i]\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(temp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cMOD9dKt2WP",
        "colab_type": "text"
      },
      "source": [
        "# Try an example image from a web URL\n",
        "\n",
        "You can also set the following variable `image_url` to point to a URL, and run the following cell to perform Mask R-CNN instance segmentation on any image. By default, we'll look at this image from a musical event from the Irish World Academy of Music and Dance ![Social Singing Event](https://www.ul.ie/sites/default/files/user_media/Social%20Singing%20Event.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mPC9fQBixss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import urllib\n",
        " \n",
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\ttemp_image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\ttemp_image = cv2.imdecode(temp_image, cv2.IMREAD_COLOR)\n",
        "\ttemp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB) # OpenCV defaults to BGR, but we need RGB here..\n",
        "\treturn temp_image\n",
        "\n",
        "# read in test image\n",
        "image_url = \"https://www.ul.ie/sites/default/files/user_media/Social%20Singing%20Event.jpg\"\n",
        "image = url_to_image(image_url)\n",
        "\n",
        "# Run detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDrb7HVvc-sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}