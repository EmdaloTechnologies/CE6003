{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_4_1_MNIST with ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtEVSXsCIycs",
        "colab_type": "text"
      },
      "source": [
        "# Handwritten Digit Recognition using a Neural Network\n",
        "\n",
        "In this lab, we're going to train a very simple neural network to recognise hardwritten digits. We're going to use the MNIST database of handwritten digits - http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "We will use the Keras API for TensorFlow 2 in this exmaple, along with NumPy, the Python library for multi-dimensional numerical computing.\n",
        "\n",
        "Let's now import TensorFlow 2 and NumPy into our Python runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOb5kfVYIywp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rBg98xZGQBE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To ensure these labs run as fast as possible, from the menu above select **Edit > Notebook settings** or **Runtime > Change runtime type** and select GPU as the Hardware accelerator option.\n",
        "\n",
        "Let's test that we are running using the GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ylv348BGS-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYTUaEdVG5l9",
        "colab_type": "text"
      },
      "source": [
        "**If** this outputs '', then we are running on CPU only. If it outputs something like '/device:GPU:0' then we are running on GPU. If you see something like ...\n",
        "\n",
        "    Failed to assign a backend\n",
        "    No backend with GPU available. WOuld you like to use a runtime with no accelerator?\n",
        "\n",
        "This suggests that many other users have all the GPU resources on colab occupied at the moment, so perhaps try later or try using with the TPU instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiVH2wQBH5gY",
        "colab_type": "text"
      },
      "source": [
        "## Loading our Sample Data\n",
        "\n",
        "We're going to next download and load the MNIST database of handwritten digits, using TF2.0/Keras helper functions.  \n",
        "\n",
        "This database is already conveniently split into labelled training and test sets for us - there are 60,000 training examples, and 10,000 test examples.\n",
        "\n",
        "We're going to further split the 10,000 test examples into 5,000 test set examples and 5,000 validation set examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqo7XSM1G8Iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"%d training examples, %d test examples by default\" % (len(x_train), len(x_test)))\n",
        "# We'll split our test data into test plus validation sets\n",
        "\n",
        "x_val = x_test[-5000:]\n",
        "y_val = y_test[-5000:]\n",
        "\n",
        "x_test = x_test[:-5000]\n",
        "y_test = y_test[:-5000]\n",
        "\n",
        "print(\"After splitting into test and validation sets, we have %d test examples and %d validation examples\" % (len(x_test), len(x_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGYrFwuUV68N",
        "colab_type": "text"
      },
      "source": [
        "Let's look at one of these examples - let's say `x_train[0]`..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHSFA0KFV7TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# this next line is just Jupyter Notebook magic to plot inline in the webpage...\n",
        "%matplotlib inline \n",
        "\n",
        "exemplar_index = 0\n",
        "\n",
        "plt.imshow(x_train[exemplar_index])\n",
        "plt.title(\"Training Example 0 has label \" + str(y_train[exemplar_index]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Vk2zWp2JL_O",
        "colab_type": "text"
      },
      "source": [
        "You can change the value of variable `exemplar_index` above and re-run the cell to see the data in the training set and its associated ground truth label.\n",
        "\n",
        "With MNIST, the examples are stored in a simple file format of pixels, where 0 means background and 255 means foreground. We're next going to scale our input to be in the range of 0.0 to 1.0 by dividing by 255.\n",
        "\n",
        "This achieves two things - it takes our precision from integer to 32-bit float, and it also scales our input data so that our default learning rate (and other hyperparameters) will work well.  This step is not necessary, but it does help speed things up.\n",
        "\n",
        "Remember, if you do pre-scaling like this on your training data, you must perform the same steps to any data prior to attempting prediction on it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_GAx42fHL0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, x_val = x_train/255.0, x_test / 255.0, x_val / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo4HoXgKYRai",
        "colab_type": "text"
      },
      "source": [
        "## Creating and Configuring our Model\n",
        "\n",
        "We're create a few variables that can be used to store important model parameters and hyper parameters for modification layer on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXvucgRVYasr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 10\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4zlR04_Yf1A",
        "colab_type": "text"
      },
      "source": [
        "Now, we will create our fully connected neural network model. This isn't a convolutional model, but a fully connected model, and as you'll see it is quite simple - with only a few layers, and approximately 100,000 trainable parameters. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de4CRcVlHVhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  # our input layer will take 28x28 images, and \"flatten\" them to 784x1\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28), name=\"flatten\"), \n",
        "\n",
        "  # next, we'll have a densely connected layer using ReLU as its activation function\n",
        "  tf.keras.layers.Dense(128, activation='relu', name=\"fc_with_ReLU\"), \n",
        "\n",
        "  # we'll add some dropout, which is a form of regularisation - \n",
        "  # you can experiment with removing this and seeing what difference it makes\n",
        "  tf.keras.layers.Dropout(dropout_rate, name=\"dropout\"), \n",
        "\n",
        "  # finally, a densely connected layer with softmax as a classifier\n",
        "  tf.keras.layers.Dense(10, activation='softmax', name=\"fc_softmax_classifier\")\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpOb2bMBQyBP",
        "colab_type": "text"
      },
      "source": [
        "You can find out more about the types of layers supported in the Keras API at https://keras.io/layers/core/\n",
        "\n",
        "Let's have a quick look at the model we just created..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6-mVOBFQ0LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.summary(), '\\n')\n",
        "\n",
        "tf.keras.utils.plot_model(model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bupzYhxCQ1Dl",
        "colab_type": "text"
      },
      "source": [
        "## Training our Model\n",
        "\n",
        "Okay, now time to compile the model, and to training it.\n",
        "\n",
        "Compiling, in Keras, configures the model for training - it defines the loss function, the optimizer and metrics. \n",
        "\n",
        "It doesn't affect or modify the weights, and you can compile a model as often as you want without affecting pretrained weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN2Q8zCvHbp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1RauElzUBO4",
        "colab_type": "text"
      },
      "source": [
        "Just before we training our model (\"fit\" it to our data), it will be initialised with random weights. Let's see how it performs against our training data *before* we train it..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFQs4OMKUITk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_train,  y_train, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y0Ua1ZkUL0P",
        "colab_type": "text"
      },
      "source": [
        "Not terribly impressive - but that is just from random weight assigments. Let's now optimize our weights to improve our prediction score against our training data and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNvWzT8RHeUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs=num_epochs, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b5z0DZFslTe",
        "colab_type": "text"
      },
      "source": [
        "In the dictionary variable `history`, we have a record of the training and test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFlP82BzsGkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWcxLyN2SnGr",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating the Performance of our Trained Model against our Validation Set\n",
        "\n",
        "Okay, let's now see how well our trained model works on our validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chlg2_6RSnXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_val,  y_val, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56kXvh0sbJWZ",
        "colab_type": "text"
      },
      "source": [
        "At this point, consider going back and changing the `num_epochs` from 5 to, say, 25 and repeating the exercise.  Does our model look like it is overfitting at any point?\n",
        "\n",
        "Or changing the `dropout_rate` from 0.2 to, say, 0.1 or 0.3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRLWymupbdTP",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the Performance against our Test Set\n",
        "\n",
        "We reserved our test set to better understand the impact our training and hyper parameter experiments had in generalising to unseen data. We can now evaluate our performance against our test set.\n",
        "\n",
        "We can evaluate our model against our test set and get a figure for overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgbG5eugbLBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_test, y_test, verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8V-ASaluBh0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We can also plot our history from training, and view our training curves - that is, the record of our training set accuracy/loss vs our test set accuracy/loss per epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7BaqD6buBvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l_yPXXDbQN4",
        "colab_type": "text"
      },
      "source": [
        "And we can use `model.predict()` to make new predictions for any unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL9JeouhQJTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exemplar_index = 0\n",
        "\n",
        "plt.imshow(x_val[exemplar_index])\n",
        "\n",
        "predictions = model.predict(x_val)\n",
        "\n",
        "print(\"For item %d, our prediction scores across all classes (\\\"0\\\" through \\\"9\\\") are %s\\n\" \n",
        "      % (exemplar_index, np.array_str(predictions[exemplar_index])))\n",
        "\n",
        "#\n",
        "# We're going to select the column corresponding to the highest prediction\n",
        "# np.amax picks the highest value in an array, and np.where identifies the column\n",
        "guess = np.where(predictions[exemplar_index] == np.amax(predictions[exemplar_index]))\n",
        "# the shape of guess from the previous operation is a 1x1 array, so we need to \n",
        "# convert this to a scalar\n",
        "guess = np.squeeze(guess, axis=(0,1)).item()\n",
        "\n",
        "print(\"Our best prediction is %d, and the ground truth is %d.\" \n",
        "      % (guess, y_val[exemplar_index]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz4OuMLmU049",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# Experiments \n",
        "\n",
        "1. If you haven't already, try changing `num_epochs` above from 5 to, say, 25 and re-training and re-evaluating.  Can you see the different in accuracy for training for longer? Does our model look like it is overfitting at any point?\n",
        "\n",
        "2. Try changing the `dropout_rate` from 0.2 to, say, 0.1 or 0.3. What is the effect?\n",
        "\n",
        "3. Try commenting out the dropout layer entirely from our model definition above, and re-running. Can you see the impact of the dropout layer in our performance on the test data? \n",
        "\n",
        "\n",
        "    # tf.keras.layers.Dropout(dropout_rate, name=\"dropout\"), # we'll add some dropout\n",
        "\n",
        "4. Try scanning some of your own handwriting for a digit, and storing it as 28x28 pixel image. Then load the image, and perform a prediction on it. The following code will allow you to upload it to Colab and run a prediction on it... (**Note:** somethings `file.upload()` method can be flakey - if you get an error along the lines of `MessageError: TypeError: Cannot read property '_uploadFiles' of undefined`, run the following cell again...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9dW71_4rUX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload an image file\n",
        "from google.colab import files\n",
        "\n",
        "uploaded_image = None\n",
        "\n",
        "uploaded_image = files.upload()\n",
        "\n",
        "import io\n",
        "import cv2\n",
        "\n",
        "if (uploaded_image != {}):\n",
        "  # convert the uploaded image data into an OpenCV grayscale inverted image,\n",
        "  # 28x28, as used by the MNIST data\n",
        "  image_stream = io.BytesIO(uploaded_image[list(uploaded_image.keys())[0]])                        \n",
        "  image = cv2.imdecode(np.frombuffer(image_stream.read(), np.uint8),1)\n",
        "  image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
        "  image = cv2.bitwise_not(image) # invert image\n",
        "  image = cv2.resize(image, (28,28))\n",
        "\n",
        "  plt.imshow(image)\n",
        "\n",
        "  # now, we're rescale our image from 0-255 to 0.0-1.0, and reshape it as an\n",
        "  # array for input into model.predict\n",
        "  model_input = image/255.0\n",
        "  model_input = np.reshape(model_input, (1, 28, 28))\n",
        "  predictions = model.predict(model_input)\n",
        "\n",
        "  # finally, we'll print out all our prediction scores and\n",
        "  # our best guess for the digit\n",
        "  print(\"Our prediction scores across all classes (\\\"0\\\" through \\\"9\\\") are %s\\n\" \n",
        "      % (np.array_str(predictions[0])))\n",
        "  guess = np.where(predictions[0] == np.amax(predictions[0]))\n",
        "  guess = np.squeeze(guess, axis=(0,1)).item()\n",
        "  print(\"Our best prediction is %d\" % (guess))\n",
        "else:\n",
        "  print(\"An image was not successfully uploaded - try again!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyIHP2aQkv3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}